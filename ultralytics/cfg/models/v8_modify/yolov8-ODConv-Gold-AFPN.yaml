# Ultralytics YOLO 🚀, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [ 0.33, 0.25, 2048 ]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [ 0.33, 0.50, 1024 ]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [ 0.67, 0.75, 768 ]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [ 1.00, 1.00, 512 ]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [ 1.00, 1.25, 512 ]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [ -1, 1, Conv, [ 64, 3, 2 ] ]  # 0-P1/2
  - [ -1, 1, Conv, [ 128, 3, 2 ] ]  # 1-P2/4
  - [ -1, 3, C2f, [ 128, True ] ]
  - [ -1, 1, Conv, [ 256, 3, 2 ] ]  # 3-P3/8
  #  - [ -1, 6, C2f_ODConv, [ 256, True ] ]
  - [ -1, 6, C2f, [ 256, True ] ]
  - [ -1, 1, Conv, [ 512, 3, 2 ] ]  # 5-P4/16
  #  - [ -1, 6, C2f_ODConv, [ 512, True ] ]
  - [ -1, 6, C2f, [ 512, True ] ]
  - [ -1, 1, Conv, [ 1024, 3, 2 ] ]  # 7-P5/32
  - [ -1, 3, C2f, [ 1024, True ] ]
  - [ -1, 1, SPPF, [ 1024, 5 ] ]  # 9
#  - [ -1, 1, ASCPA, [ 1024 ] ]  # 10

# YOLOv8.0n head
head:
  # low-gd
  - [ [ 2, 4, 6, -1 ], 1, Low_FAM, [ ] ]  # 11
  # Low_IFM的输出通道会split2个全局特征,分别注入到B3,B4中,它们通道数分别为256*w,512*w,
  # 以yolv8n举例,width=0.25, 因此通道分别为64,128. 这也是split的参数. 于是low_ifm输出的
  # 通道:num*0.25=64+128, num=768, 这里把split部分写入了Low_IFM模块,避免在task.py中引入
  # 不必要的模块, 96:中间通道数, 3: 融合模块RepVGGBlock重复次数,
  # 注意split通道参数[128,64]写在Low_IFM模块中,不收width影响, 要事先精确计算出来.
  # 为什么是[128,64],而不是[64,128]? 因为128对应B4, 先注入B4,用注入后的结果替代原来的B4进行下面的操作
  - [ -1, 1, Low_IFM, [ 768, 96, 3, [ 128, 64 ] ] ] # 12-low_global_info

  # SimConv作用是通道减半,不能合并到Low_LAF中,因为输出值
  # 在其他地方也会用到, 下面的SimConv功能也是如此, 第10层输出通道1024,输出512, 他们都受width影响.
  - [ 9, 1, SimConv, [ 512, 1, 1 ] ] # 13-c5_half
  # B3,B4,B5,Low_LAF的输出对齐B4的shape,B4输出512,因此Low_LAF输出通道数也是512,
  - [ [ 4, 6, -1 ], 1, Low_LAF, [ 512 ] ] # 14
  # Low_IFM有两个全局输出特征, 0号特征64,注入B3中,3:整合注入信息的RepBlock重复次数
  # RepBlock是当前分支Inject结果的整合,不改变通道数,下同
  - [ [ -1, 12 ], 1, Inject, [ 512, 0, 3 ] ]  # 15 - out1

  # 使用注入后的B4进行LAF操作
  - [ -1, 1, SimConv, [ 256, 1, 1 ] ] # 16-p4_half
  # B2,B3,B4,
  - [ [ 2, 4, -1 ], 1, Low_LAF, [ 256 ] ] # 17
  # 1号特征通道数128,注入B4中
  - [ [ -1, 12 ], 1, Inject, [ 256, 1, 3 ] ]  # 18

  # high-gd
  - [ [ -1, 15, 9 ], 1, High_FAM, [ 1, 'torch' ] ]  # 19
  # High_IFM的输出通道数不能适配上下两个注入层,需要加卷积调节通道数,High_IFM不改变通道数,因此卷积参数为:
  # 输入=1792*0.25=448, 输出=(1024+512)*0.25=384, split通道为128,256
  - [ -1, 1, High_IFM, [ 2, 704, 8, 4,[ 448,384, 1, 1, 0 ],[ 128, 256 ], 1, 2, 0, [ 0.1, 2 ] ] ] # 20
  #  - [ -1, 1, nn.Conv2d, [ 1536, 1, 1, 0 ] ]
  #  - [ -1, 1, Split, [ 512, 1024 ] ] # 24-high_global_info

  - [ [ 21, 18 ], 1, High_LAF, [ ] ]  # 21
  - [ [ -1, 25 ], 1, Inject, [ 512, 0, 3 ] ]  #22 - out2
  #  - [ -1, 12, RepBlock, [ 512 ] ] # 27-n4

  - [ [ -1, 14 ], 1, High_LAF, [ ] ]  # 23
  - [ [ -1, 25 ], 1, Inject, [ 1024, 1, 3 ] ] # 24 - out3
  #  - [ -1, 12, RepBlock, [ 1024 ] ] # 30-n5


  #  - [ [ 21, 28, 31 ], 1, Detect, [ nc ] ]  # Detect(P3, P4, P5)
  - [ [ 13, 22, 24 ], 1, Detect, [ nc ] ]  # Detect(P3, P4, P5)
  #    - [ [ 15, 18, 21 ], 1, Detect_AFPN3, [ nc, 256 ] ]  # Detect(P3, P4, P5)

#  - [ [ 21, 28, 31 ], 1, Detect_AFPN3, [ nc, 256 ] ]  # Detect(P3, P4, P5)
